{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817cfd59-a54b-4394-9656-9d0e79711d0c",
   "metadata": {},
   "source": [
    "### **Load Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc69a03-0055-4ae8-91d9-52ebb078f872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15064\\3884275074.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "\n",
    "# from config import oltp_conn_string, warehouse_conn_string, oltp_tables, warehouse_tables, dimension_columns, ddl_statements, ddl_marts\n",
    "from config_local import oltp_conn_string_local, warehouse_conn_string_local, oltp_tables, warehouse_tables, dimension_columns, ddl_statements, ddl_marts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f36d37-dd56-4c5f-8690-dd88bc6f510f",
   "metadata": {},
   "source": [
    "### **Function ETL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff56c09-846c-49c5-84c3-1491ffd98082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_tables():\n",
    "    \"\"\"Create tables in the data warehouse if they do not exist.\"\"\"\n",
    "    engine = sa.create_engine(warehouse_conn_string_local)\n",
    "    with engine.connect() as conn:\n",
    "        for ddl in ddl_statements.values():\n",
    "            conn.execute(ddl)\n",
    "            \n",
    "def extract_data(table_name):\n",
    "    \"\"\"Extract data from a table in the OLTP database.\"\"\"\n",
    "    engine = sa.create_engine(oltp_conn_string_local)\n",
    "    query = f\"SELECT * FROM {oltp_tables[table_name]}\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(f'Extract Data {oltp_tables[table_name]} Success')\n",
    "    return df\n",
    "\n",
    "def transform_data(df, target_table):\n",
    "    \"\"\"Transform the extracted data to match the schema of the target dimension table.\"\"\"\n",
    "    columns = dimension_columns.get(target_table)\n",
    "    if columns:\n",
    "        df = df[columns]\n",
    "    print(f'Transform Data {target_table} Success')\n",
    "    return df\n",
    "\n",
    "def transform_fact_orders():\n",
    "    \"\"\"Transform data for the fact_orders table.\"\"\"\n",
    "    dataframes = {table: extract_data(table) for table in oltp_tables.keys()}\n",
    "    for table_name, df in dataframes.items():\n",
    "        print(f\"Columns in {table_name}: {df.columns.tolist()}\")\n",
    "    # Join order_items with orders to bring in user_id and other columns\n",
    "    df_order_items = dataframes['order_items']\n",
    "    df_orders = dataframes['orders']\n",
    "    \n",
    "    # Exclude rows with missing product_id\n",
    "    df_order_items = df_order_items[df_order_items['product_id'].notnull()]\n",
    "    df_fact_orders = df_order_items.merge(df_orders, on='order_id')\n",
    "\n",
    "    # Merge with other dimension tables\n",
    "    df_fact_orders = df_fact_orders.merge(dataframes['users'], on='user_id')\n",
    "    df_fact_orders = df_fact_orders.merge(dataframes['products'], on='product_id')\n",
    "    df_fact_orders = df_fact_orders.merge(dataframes['product_category'], on='product_category_id')\n",
    "    df_fact_orders = df_fact_orders.merge(dataframes['payments'], on='payment_id')\n",
    "    df_fact_orders = df_fact_orders.merge(dataframes['shippers'], on='shipper_id')\n",
    "    df_fact_orders = df_fact_orders.merge(dataframes['ratings'], on='rating_id')\n",
    "    df_fact_orders = df_fact_orders.merge(dataframes['vouchers'], how='left', on='voucher_id')\n",
    "\n",
    "    df_fact_orders.rename(columns={'user_id_x': 'user_id'}, inplace=True)\n",
    "    \n",
    "    fact_orders_columns = dimension_columns.get('fact_orders')\n",
    "    return df_fact_orders[fact_orders_columns]\n",
    "\n",
    "\n",
    "# def load_data(df, table_name):\n",
    "#     \"\"\"Load the transformed data into the target table in the data warehouse.\"\"\"\n",
    "#     engine = sa.create_engine(warehouse_conn_string_local)\n",
    "    \n",
    "#     with engine.connect() as conn:\n",
    "#         # Cek kunci unique\n",
    "#         unique_key = get_unique_key(table_name) \n",
    "#         # Misalnya user_id untuk tabel dim_user\n",
    "#         existing_data = pd.read_sql(f\"SELECT {unique_key} FROM {table_name}\", conn)\n",
    "#         #print(existing_data)\n",
    "#         # Deduplikasi data\n",
    "#         df = deduplicate_data(df, existing_data, unique_key)\n",
    "#         print(df.shape)\n",
    "#         # Masukkan data baru\n",
    "#         df.to_sql(table_name, conn, index=False, if_exists='append', method='multi')\n",
    "#         print(df.shape)\n",
    "#         print(f'Load Data {table_name} Success')\n",
    "\n",
    "def load_data(df, table_name):\n",
    "    \"\"\"Load the transformed data into the target table in the data warehouse.\"\"\"\n",
    "    engine = sa.create_engine(warehouse_conn_string_local)\n",
    "    # Cek kunci unique\n",
    "    unique_key = get_unique_key(table_name) \n",
    "    # Misalnya user_id untuk tabel dim_user\n",
    "    existing_data = pd.read_sql(f\"SELECT {unique_key} FROM {table_name}\", engine)\n",
    "    #print(existing_data)\n",
    "    # Deduplikasi data\n",
    "    df = deduplicate_data(df, existing_data, unique_key)\n",
    "    print(df.shape)\n",
    "    # Masukkan data baru\n",
    "    df.to_sql(table_name, engine, index=False, if_exists='append', method='multi')\n",
    "    print(df.shape)\n",
    "    print(f'Load Data {table_name} Success')\n",
    "        \n",
    "def deduplicate_data(new_data, existing_data, unique_key):\n",
    "    \"\"\"Remove duplicates from new data based on existing data.\"\"\"\n",
    "    #print(new_data)\n",
    "    existing_keys = existing_data[unique_key].tolist()\n",
    "    #print(existing_keys)\n",
    "    unique_rows = new_data[~new_data[unique_key].isin(existing_keys)]\n",
    "    #print(unique_rows)\n",
    "    return unique_rows\n",
    "\n",
    "def get_unique_key(table_name):\n",
    "    \"\"\"Retrieve the unique key of the table.\"\"\"\n",
    "    if table_name == 'dim_user':\n",
    "        return 'user_id'\n",
    "    if table_name == 'dim_product':\n",
    "        return 'product_id'\n",
    "    if table_name == \"dim_product_category\":\n",
    "        return 'product_category_id'\n",
    "    elif table_name == 'dim_payment':\n",
    "        return 'payment_id'\n",
    "    elif table_name == 'dim_shipper':\n",
    "        return 'shipper_id'\n",
    "    elif table_name == 'dim_rating':\n",
    "        return 'rating_id'\n",
    "    elif table_name == 'dim_voucher':\n",
    "        return 'voucher_id'\n",
    "    elif table_name == 'fact_orders':\n",
    "        return 'order_id'\n",
    "    # Tambahkan kondisi lain jika ada tabel lain\n",
    "    else:\n",
    "        raise ValueError(\"Table name not recognized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0dab5-2f9d-472d-8350-ad46d2e7e60a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Function Data Mart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d93de0d-ea8e-422d-aa68-1c1132427704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_and_insert_dm_sales():\n",
    "    \"\"\"Create dm_sales table and insert data into it.\"\"\"\n",
    "    engine = sa.create_engine(warehouse_conn_string_local)\n",
    "    with engine.connect() as conn:\n",
    "        # Create dm_sales table\n",
    "        conn.execute(ddl_marts['dim_sales'])\n",
    "\n",
    "        # Insert data into dm_sales table\n",
    "        conn.execute(ddl_marts['insert_dm_sales'])\n",
    "    print(f'Data Mart Has Create Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09cd1cd-e9ac-4a99-91f2-f3b9dcc28312",
   "metadata": {},
   "source": [
    "### **Function Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10330d98-0373-42aa-8307-caa46e6bf0ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def etl_process():\n",
    "    \"\"\"Run the entire ETL process.\"\"\"\n",
    "    # Create tables\n",
    "    #create_tables()\n",
    "\n",
    "    # Process dimension tables\n",
    "    for dim_table, target_table in warehouse_tables.items():\n",
    "        #if dim_table != 'fact_orders':\n",
    "        if dim_table != 'orders':\n",
    "            print(dim_table)\n",
    "            source_table = dim_table\n",
    "            df = extract_data(source_table)\n",
    "            transformed_df = transform_data(df, dim_table)\n",
    "            load_data(transformed_df, target_table)\n",
    "        else:\n",
    "            # Process fact table\n",
    "            df_fact_orders = transform_fact_orders()\n",
    "            load_data(df_fact_orders, target_table)\n",
    "\n",
    "    # proses mart table\n",
    "    create_and_insert_dm_sales()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f468a-fb5f-476f-a7d0-5cca7d859a96",
   "metadata": {},
   "source": [
    "# **Run ETL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2738ed9d-6512-4f11-b7be-400976529462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users\n",
      "Extract Data tb_users Success\n",
      "Transform Data users Success\n",
      "(0, 7)\n",
      "(0, 7)\n",
      "Load Data dim_user Success\n",
      "product_category\n",
      "Extract Data tb_product_category Success\n",
      "Transform Data product_category Success\n",
      "(0, 2)\n",
      "(0, 2)\n",
      "Load Data dim_product_category Success\n",
      "products\n",
      "Extract Data tb_products Success\n",
      "Transform Data products Success\n",
      "(0, 6)\n",
      "(0, 6)\n",
      "Load Data dim_product Success\n",
      "payments\n",
      "Extract Data tb_payments Success\n",
      "Transform Data payments Success\n",
      "(0, 3)\n",
      "(0, 3)\n",
      "Load Data dim_payment Success\n",
      "shippers\n",
      "Extract Data tb_shippers Success\n",
      "Transform Data shippers Success\n",
      "(0, 2)\n",
      "(0, 2)\n",
      "Load Data dim_shipper Success\n",
      "ratings\n",
      "Extract Data tb_ratings Success\n",
      "Transform Data ratings Success\n",
      "(0, 3)\n",
      "(0, 3)\n",
      "Load Data dim_rating Success\n",
      "vouchers\n",
      "Extract Data tb_vouchers Success\n",
      "Transform Data vouchers Success\n",
      "(0, 5)\n",
      "(0, 5)\n",
      "Load Data dim_voucher Success\n",
      "Extract Data tb_users Success\n",
      "Extract Data tb_product_category Success\n",
      "Extract Data tb_products Success\n",
      "Extract Data tb_payments Success\n",
      "Extract Data tb_shippers Success\n",
      "Extract Data tb_ratings Success\n",
      "Extract Data tb_vouchers Success\n",
      "Extract Data tb_orders Success\n",
      "Extract Data tb_order_items Success\n",
      "Columns in users: ['user_id', 'user_first_name', 'user_last_name', 'user_gender', 'user_address', 'user_birthday', 'user_join']\n",
      "Columns in product_category: ['product_category_id', 'product_category_name']\n",
      "Columns in products: ['product_id', 'product_category_id', 'product_name', 'product_created', 'product_price', 'product_discount']\n",
      "Columns in payments: ['payment_id', 'payment_name', 'payment_status']\n",
      "Columns in shippers: ['shipper_id', 'shipper_name']\n",
      "Columns in ratings: ['rating_id', 'rating_level', 'rating_status']\n",
      "Columns in vouchers: ['voucher_id', 'voucher_name', 'voucher_price', 'voucher_created', 'user_id']\n",
      "Columns in orders: ['order_id', 'order_date', 'user_id', 'payment_id', 'shipper_id', 'order_price', 'order_discount', 'voucher_id', 'order_total', 'rating_id']\n",
      "Columns in order_items: ['order_item_id', 'order_id', 'product_id', 'order_item_quantity', 'product_discount', 'product_subdiscount', 'product_price', 'product_subprice']\n",
      "(22, 10)\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(psycopg2.errors.NotNullViolation) null value in column \"product_id\" of relation \"fact_orders\" violates not-null constraint\nDETAIL:  Failing row contains (1110001, 2022-01-20, 100101, null, 1202, 60002001, 250000, 15000, 41000101, 230000, 800010003).\n\n[SQL: INSERT INTO fact_orders (order_id, order_date, user_id, payment_id, shipper_id, order_price, order_discount, voucher_id, order_total, rating_id) VALUES (%(order_id__0)s, %(order_date__0)s, %(user_id__0)s, %(payment_id__0)s, %(shipper_id__0)s, %(order ... 4144 characters truncated ... der_price__21)s, %(order_discount__21)s, %(voucher_id__21)s, %(order_total__21)s, %(rating_id__21)s)]\n[parameters: {'voucher_id__0': 41000101.0, 'order_total__0': 230000, 'shipper_id__0': 60002001, 'order_date__0': datetime.date(2022, 1, 20), 'order_discount__0': 15000, 'order_id__0': 1110001, 'payment_id__0': 1202, 'order_price__0': 250000, 'user_id__0': 100101, 'rating_id__0': 800010003, 'voucher_id__1': 41000102.0, 'order_total__1': 575000, 'shipper_id__1': 60002001, 'order_date__1': datetime.date(2022, 1, 29), 'order_discount__1': 40000, 'order_id__1': 1110002, 'payment_id__1': 1202, 'order_price__1': 620000, 'user_id__1': 100102, 'rating_id__1': 800010003, 'voucher_id__2': 41000102.0, 'order_total__2': 575000, 'shipper_id__2': 60002001, 'order_date__2': datetime.date(2022, 1, 29), 'order_discount__2': 40000, 'order_id__2': 1110002, 'payment_id__2': 1202, 'order_price__2': 620000, 'user_id__2': 100102, 'rating_id__2': 800010003, 'voucher_id__3': 41000103.0, 'order_total__3': 4995000, 'shipper_id__3': 60002001, 'order_date__3': datetime.date(2022, 2, 13), 'order_discount__3': 1000000, 'order_id__3': 1110003, 'payment_id__3': 1204, 'order_price__3': 6000000, 'user_id__3': 100103, 'rating_id__3': 800010001, 'voucher_id__4': 41000103.0, 'order_total__4': 4995000, 'shipper_id__4': 60002001, 'order_date__4': datetime.date(2022, 2, 13), 'order_discount__4': 1000000, 'order_id__4': 1110003, 'payment_id__4': 1204, 'order_price__4': 6000000, 'user_id__4': 100103, 'rating_id__4': 800010001 ... 120 parameters truncated ... 'voucher_id__17': None, 'order_total__17': 1005000, 'shipper_id__17': 60002003, 'order_date__17': datetime.date(2022, 7, 1), 'order_discount__17': 45000, 'order_id__17': 1110010, 'payment_id__17': 1204, 'order_price__17': 1050000, 'user_id__17': 100102, 'rating_id__17': 800010002, 'voucher_id__18': None, 'order_total__18': 535000, 'shipper_id__18': 60002002, 'order_date__18': datetime.date(2022, 7, 21), 'order_discount__18': 15000, 'order_id__18': 1110011, 'payment_id__18': 1203, 'order_price__18': 550000, 'user_id__18': 100110, 'rating_id__18': 800010005, 'voucher_id__19': None, 'order_total__19': 535000, 'shipper_id__19': 60002002, 'order_date__19': datetime.date(2022, 7, 21), 'order_discount__19': 15000, 'order_id__19': 1110011, 'payment_id__19': 1203, 'order_price__19': 550000, 'user_id__19': 100110, 'rating_id__19': 800010005, 'voucher_id__20': 41000115.0, 'order_total__20': 445000, 'shipper_id__20': 60002001, 'order_date__20': datetime.date(2022, 7, 30), 'order_discount__20': 35000, 'order_id__20': 1110012, 'payment_id__20': 1202, 'order_price__20': 490000, 'user_id__20': 100110, 'rating_id__20': 800010004, 'voucher_id__21': 41000115.0, 'order_total__21': 445000, 'shipper_id__21': 60002001, 'order_date__21': datetime.date(2022, 7, 30), 'order_discount__21': 35000, 'order_id__21': 1110012, 'payment_id__21': 1202, 'order_price__21': 490000, 'user_id__21': 100110, 'rating_id__21': 800010004}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotNullViolation\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2104\u001b[0m, in \u001b[0;36mConnection._exec_insertmany_context\u001b[1;34m(self, dialect, context)\u001b[0m\n\u001b[0;32m   2103\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2104\u001b[0m         \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2106\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 924\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mNotNullViolation\u001b[0m: null value in column \"product_id\" of relation \"fact_orders\" violates not-null constraint\nDETAIL:  Failing row contains (1110001, 2022-01-20, 100101, null, 1202, 60002001, 250000, 15000, 41000101, 230000, 800010003).\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#script running all ETL\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43metl_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m, in \u001b[0;36metl_process\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;66;03m# Process fact table\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         df_fact_orders \u001b[38;5;241m=\u001b[39m transform_fact_orders()\n\u001b[1;32m---> 18\u001b[0m         \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_fact_orders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# proses mart table\u001b[39;00m\n\u001b[0;32m     21\u001b[0m create_and_insert_dm_sales()\n",
      "Cell \u001b[1;32mIn[8], line 82\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(df, table_name)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Masukkan data baru\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad Data \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Success\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\pandas\\core\\generic.py:3081\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2886\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2887\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2888\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3077\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3078\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3079\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3081\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3082\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3092\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\pandas\\io\\sql.py:2021\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2009\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m   2011\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[0;32m   2012\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   2013\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2018\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2019\u001b[0m )\n\u001b[1;32m-> 2021\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m \u001b[43msql_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2030\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2031\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2033\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m   2034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\pandas\\io\\sql.py:1570\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(msg, err_text):\n\u001b[0;32m   1569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf cannot be used with MySQL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m-> 1570\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\pandas\\io\\sql.py:1561\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mStatementError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1563\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[0;32m   1565\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(1054, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf(e0)?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield list\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m))(?#\u001b[39m\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;124m    )|inf can not be used with MySQL\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\pandas\\io\\sql.py:1122\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[1;32m-> 1122\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\pandas\\io\\sql.py:1030\u001b[0m, in \u001b[0;36mSQLTable._execute_insert_multi\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m   1025\u001b[0m stmt \u001b[38;5;241m=\u001b[39m insert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# conn.execute is used here to ensure compatibility with Oracle.\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# Using stmt.values(data) would produce a multi row insert that\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;66;03m# isn't supported by Oracle.\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;66;03m# see: https://docs.sqlalchemy.org/en/20/core/dml.html#sqlalchemy.sql.expression.Insert.values\u001b[39;00m\n\u001b[1;32m-> 1030\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1408\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:513\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1630\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1618\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1620\u001b[0m )\n\u001b[0;32m   1622\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1623\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1624\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1629\u001b[0m )\n\u001b[1;32m-> 1630\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1644\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1645\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1649\u001b[0m         ret,\n\u001b[0;32m   1650\u001b[0m     )\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1834\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1831\u001b[0m context\u001b[38;5;241m.\u001b[39mpre_exec()\n\u001b[0;32m   1833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecute_style \u001b[38;5;129;01mis\u001b[39;00m ExecuteStyle\u001b[38;5;241m.\u001b[39mINSERTMANYVALUES:\n\u001b[1;32m-> 1834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_insertmany_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1837\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1839\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_single_context(\n\u001b[0;32m   1840\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1841\u001b[0m     )\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2112\u001b[0m, in \u001b[0;36mConnection._exec_insertmany_context\u001b[1;34m(self, dialect, context)\u001b[0m\n\u001b[0;32m   2104\u001b[0m         dialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[0;32m   2105\u001b[0m             cursor,\n\u001b[0;32m   2106\u001b[0m             sub_stmt,\n\u001b[0;32m   2107\u001b[0m             sub_params,\n\u001b[0;32m   2108\u001b[0m             context,\n\u001b[0;32m   2109\u001b[0m         )\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2113\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2114\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_long_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2115\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_sub_exec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine_events:\n\u001b[0;32m   2122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   2123\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2124\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2128\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   2129\u001b[0m     )\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2335\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2333\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2334\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2337\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2104\u001b[0m, in \u001b[0;36mConnection._exec_insertmany_context\u001b[1;34m(self, dialect, context)\u001b[0m\n\u001b[0;32m   2102\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   2103\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2104\u001b[0m         \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2106\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[0;32m   2113\u001b[0m         e,\n\u001b[0;32m   2114\u001b[0m         sql_util\u001b[38;5;241m.\u001b[39m_long_statement(sub_stmt),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2118\u001b[0m         is_sub_exec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2119\u001b[0m     )\n",
      "File \u001b[1;32md:\\python_projects\\web_scraping\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 924\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIntegrityError\u001b[0m: (psycopg2.errors.NotNullViolation) null value in column \"product_id\" of relation \"fact_orders\" violates not-null constraint\nDETAIL:  Failing row contains (1110001, 2022-01-20, 100101, null, 1202, 60002001, 250000, 15000, 41000101, 230000, 800010003).\n\n[SQL: INSERT INTO fact_orders (order_id, order_date, user_id, payment_id, shipper_id, order_price, order_discount, voucher_id, order_total, rating_id) VALUES (%(order_id__0)s, %(order_date__0)s, %(user_id__0)s, %(payment_id__0)s, %(shipper_id__0)s, %(order ... 4144 characters truncated ... der_price__21)s, %(order_discount__21)s, %(voucher_id__21)s, %(order_total__21)s, %(rating_id__21)s)]\n[parameters: {'voucher_id__0': 41000101.0, 'order_total__0': 230000, 'shipper_id__0': 60002001, 'order_date__0': datetime.date(2022, 1, 20), 'order_discount__0': 15000, 'order_id__0': 1110001, 'payment_id__0': 1202, 'order_price__0': 250000, 'user_id__0': 100101, 'rating_id__0': 800010003, 'voucher_id__1': 41000102.0, 'order_total__1': 575000, 'shipper_id__1': 60002001, 'order_date__1': datetime.date(2022, 1, 29), 'order_discount__1': 40000, 'order_id__1': 1110002, 'payment_id__1': 1202, 'order_price__1': 620000, 'user_id__1': 100102, 'rating_id__1': 800010003, 'voucher_id__2': 41000102.0, 'order_total__2': 575000, 'shipper_id__2': 60002001, 'order_date__2': datetime.date(2022, 1, 29), 'order_discount__2': 40000, 'order_id__2': 1110002, 'payment_id__2': 1202, 'order_price__2': 620000, 'user_id__2': 100102, 'rating_id__2': 800010003, 'voucher_id__3': 41000103.0, 'order_total__3': 4995000, 'shipper_id__3': 60002001, 'order_date__3': datetime.date(2022, 2, 13), 'order_discount__3': 1000000, 'order_id__3': 1110003, 'payment_id__3': 1204, 'order_price__3': 6000000, 'user_id__3': 100103, 'rating_id__3': 800010001, 'voucher_id__4': 41000103.0, 'order_total__4': 4995000, 'shipper_id__4': 60002001, 'order_date__4': datetime.date(2022, 2, 13), 'order_discount__4': 1000000, 'order_id__4': 1110003, 'payment_id__4': 1204, 'order_price__4': 6000000, 'user_id__4': 100103, 'rating_id__4': 800010001 ... 120 parameters truncated ... 'voucher_id__17': None, 'order_total__17': 1005000, 'shipper_id__17': 60002003, 'order_date__17': datetime.date(2022, 7, 1), 'order_discount__17': 45000, 'order_id__17': 1110010, 'payment_id__17': 1204, 'order_price__17': 1050000, 'user_id__17': 100102, 'rating_id__17': 800010002, 'voucher_id__18': None, 'order_total__18': 535000, 'shipper_id__18': 60002002, 'order_date__18': datetime.date(2022, 7, 21), 'order_discount__18': 15000, 'order_id__18': 1110011, 'payment_id__18': 1203, 'order_price__18': 550000, 'user_id__18': 100110, 'rating_id__18': 800010005, 'voucher_id__19': None, 'order_total__19': 535000, 'shipper_id__19': 60002002, 'order_date__19': datetime.date(2022, 7, 21), 'order_discount__19': 15000, 'order_id__19': 1110011, 'payment_id__19': 1203, 'order_price__19': 550000, 'user_id__19': 100110, 'rating_id__19': 800010005, 'voucher_id__20': 41000115.0, 'order_total__20': 445000, 'shipper_id__20': 60002001, 'order_date__20': datetime.date(2022, 7, 30), 'order_discount__20': 35000, 'order_id__20': 1110012, 'payment_id__20': 1202, 'order_price__20': 490000, 'user_id__20': 100110, 'rating_id__20': 800010004, 'voucher_id__21': 41000115.0, 'order_total__21': 445000, 'shipper_id__21': 60002001, 'order_date__21': datetime.date(2022, 7, 30), 'order_discount__21': 35000, 'order_id__21': 1110012, 'payment_id__21': 1202, 'order_price__21': 490000, 'user_id__21': 100110, 'rating_id__21': 800010004}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "#script running all ETL\n",
    "etl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e1fec-86cb-4426-bc7b-28b5ab27efec",
   "metadata": {},
   "source": [
    "### **Run Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ba73e31-b2fe-478c-bad1-b756ad924fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Data tb_product_category Success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_id</th>\n",
       "      <th>product_category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320001001</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320001002</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320001003</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_category_id product_category_name\n",
       "0            320001001               Fashion\n",
       "1            320001002            Electronic\n",
       "2            320001003       Health & Beauty"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create_tables()\n",
    "\n",
    "source_table = 'product_category'\n",
    "df = extract_data(source_table)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6af6dfee-7af4-412b-9dc4-537ec3689526",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Data dim_user Success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_first_name</th>\n",
       "      <th>user_last_name</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_address</th>\n",
       "      <th>user_birthday</th>\n",
       "      <th>user_join</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100101</td>\n",
       "      <td>Budi</td>\n",
       "      <td>Gunawan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jl. Pondok Indah No.1, Kecamatan Pondok Labu, ...</td>\n",
       "      <td>1998-09-12</td>\n",
       "      <td>2022-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100102</td>\n",
       "      <td>Eva</td>\n",
       "      <td>Susanti</td>\n",
       "      <td>Female</td>\n",
       "      <td>Jl. Timur Raya No. 13, Kramat Jaya, Jakarta Ti...</td>\n",
       "      <td>1997-02-16</td>\n",
       "      <td>2022-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100103</td>\n",
       "      <td>Dana</td>\n",
       "      <td>Pradana</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jl. Pahlawan, Surabaya, Jawa Timur</td>\n",
       "      <td>1999-07-19</td>\n",
       "      <td>2022-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100104</td>\n",
       "      <td>Rahmat</td>\n",
       "      <td>Hidayat</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jl. Amil Abas, Jakarta Timur, DKI Jakarta</td>\n",
       "      <td>2000-02-14</td>\n",
       "      <td>2022-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100105</td>\n",
       "      <td>Dodo</td>\n",
       "      <td>Andriano</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jl. Pakuan Selatan No. 177, Magelang, Jawa Tengah</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>2022-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100106</td>\n",
       "      <td>Caca</td>\n",
       "      <td>Kumala</td>\n",
       "      <td>Female</td>\n",
       "      <td>Jl. Bunga Raya, Kota Tanggerang, Banten</td>\n",
       "      <td>1998-11-05</td>\n",
       "      <td>2022-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100107</td>\n",
       "      <td>Andi</td>\n",
       "      <td>Kurniawan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jl. Mawar Indah No. 25, Jakarta Barat, DKI Jak...</td>\n",
       "      <td>2001-03-14</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100108</td>\n",
       "      <td>Fanny</td>\n",
       "      <td>Utami</td>\n",
       "      <td>Female</td>\n",
       "      <td>Jl. Kilometer Panjang No. 210, Jakarta Utara, ...</td>\n",
       "      <td>2002-01-27</td>\n",
       "      <td>2022-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100109</td>\n",
       "      <td>Gagah</td>\n",
       "      <td>Prakasa</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jl. Timur Asri No. 10, Denpasar, Bali</td>\n",
       "      <td>2001-08-05</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100110</td>\n",
       "      <td>Anita</td>\n",
       "      <td>Friska</td>\n",
       "      <td>Female</td>\n",
       "      <td>Jl. Tembung Raya, Kota Medan Timur, Sumatera U...</td>\n",
       "      <td>2000-11-04</td>\n",
       "      <td>2022-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id user_first_name user_last_name user_gender  \\\n",
       "0   100101            Budi        Gunawan        Male   \n",
       "1   100102             Eva        Susanti      Female   \n",
       "2   100103            Dana        Pradana        Male   \n",
       "3   100104          Rahmat        Hidayat        Male   \n",
       "4   100105            Dodo       Andriano        Male   \n",
       "5   100106            Caca         Kumala      Female   \n",
       "6   100107            Andi      Kurniawan        Male   \n",
       "7   100108           Fanny          Utami      Female   \n",
       "8   100109           Gagah        Prakasa        Male   \n",
       "9   100110           Anita         Friska      Female   \n",
       "\n",
       "                                        user_address user_birthday   user_join  \n",
       "0  Jl. Pondok Indah No.1, Kecamatan Pondok Labu, ...    1998-09-12  2022-01-13  \n",
       "1  Jl. Timur Raya No. 13, Kramat Jaya, Jakarta Ti...    1997-02-16  2022-01-29  \n",
       "2                 Jl. Pahlawan, Surabaya, Jawa Timur    1999-07-19  2022-02-11  \n",
       "3          Jl. Amil Abas, Jakarta Timur, DKI Jakarta    2000-02-14  2022-03-22  \n",
       "4  Jl. Pakuan Selatan No. 177, Magelang, Jawa Tengah    2000-09-06  2022-04-03  \n",
       "5            Jl. Bunga Raya, Kota Tanggerang, Banten    1998-11-05  2022-05-20  \n",
       "6  Jl. Mawar Indah No. 25, Jakarta Barat, DKI Jak...    2001-03-14  2022-05-24  \n",
       "7  Jl. Kilometer Panjang No. 210, Jakarta Utara, ...    2002-01-27  2022-06-02  \n",
       "8              Jl. Timur Asri No. 10, Denpasar, Bali    2001-08-05  2022-07-14  \n",
       "9  Jl. Tembung Raya, Kota Medan Timur, Sumatera U...    2000-11-04  2022-07-21  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df = transform_data(df, 'dim_user')\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec7ab74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 7)\n",
      "(10, 7)\n",
      "Load Data dim_user Success\n"
     ]
    }
   ],
   "source": [
    "load_data(transformed_df, 'dim_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0c95c03-3427-4248-a2ef-1dee7f556f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# with engine.connect() as conn:\n",
    "#     # Cek kunci unique\n",
    "#     unique_key = get_unique_key(\"dim_user\") \n",
    "#     #print(unique_key)\n",
    "#     # Misalnya user_id untuk tabel dim_user\n",
    "#     existing_data = pd.read_sql(f\"SELECT {unique_key} FROM dim_user\", conn)\n",
    "#     # Deduplikasi data\n",
    "#     df = deduplicate_data(df, existing_data, unique_key)\n",
    "print(df.shape)\n",
    "engine = sa.create_engine(warehouse_conn_string_local)\n",
    "df.to_sql(\"dim_user\",engine , if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afee92-a119-4e39-9afd-5aec4b238e1b",
   "metadata": {},
   "source": [
    "### **Script Upload Google Sheets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ce8176-06b3-46b7-9328-679fd00545bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "with open('digitalskola_key.json','rb') as file:\n",
    "    key = json.load(file)\n",
    "    \n",
    "scope = ['https://www.googleapis.com/auth/drive','https://spreadsheets.google.com/feeds']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_dict(key, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "###tambahkan email googledigitalskola@digitalskola-368401.iam.gserviceaccount.com ke dalam google sheet anda#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "155dce82-f692-450f-81e7-720013c3a3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>shipper_name</th>\n",
       "      <th>order_price</th>\n",
       "      <th>order_discount</th>\n",
       "      <th>voucher_name</th>\n",
       "      <th>order_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1110001</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>100101</td>\n",
       "      <td>Budi Gunawan</td>\n",
       "      <td>Debit</td>\n",
       "      <td>JNE Express</td>\n",
       "      <td>250000</td>\n",
       "      <td>15000</td>\n",
       "      <td>New User</td>\n",
       "      <td>230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1110002</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>100102</td>\n",
       "      <td>Eva Susanti</td>\n",
       "      <td>Debit</td>\n",
       "      <td>JNE Express</td>\n",
       "      <td>620000</td>\n",
       "      <td>40000</td>\n",
       "      <td>New User</td>\n",
       "      <td>575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110003</td>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>100103</td>\n",
       "      <td>Dana Pradana</td>\n",
       "      <td>Credit</td>\n",
       "      <td>JNE Express</td>\n",
       "      <td>6000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>New User</td>\n",
       "      <td>4995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1110005</td>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>100105</td>\n",
       "      <td>Dodo Andriano</td>\n",
       "      <td>Debit</td>\n",
       "      <td>Sicepat Express</td>\n",
       "      <td>4000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>New User</td>\n",
       "      <td>2995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1110008</td>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>100108</td>\n",
       "      <td>Fanny Utami</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Sicepat Express</td>\n",
       "      <td>2000000</td>\n",
       "      <td>0</td>\n",
       "      <td>New User</td>\n",
       "      <td>1995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1110012</td>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>100110</td>\n",
       "      <td>Anita Friska</td>\n",
       "      <td>Debit</td>\n",
       "      <td>JNE Express</td>\n",
       "      <td>490000</td>\n",
       "      <td>35000</td>\n",
       "      <td>Body Soap Promo</td>\n",
       "      <td>445000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  order_date  user_id      user_name payment_type     shipper_name  \\\n",
       "0   1110001  2022-01-20   100101   Budi Gunawan        Debit      JNE Express   \n",
       "1   1110002  2022-01-29   100102    Eva Susanti        Debit      JNE Express   \n",
       "2   1110003  2022-02-13   100103   Dana Pradana       Credit      JNE Express   \n",
       "3   1110005  2022-04-28   100105  Dodo Andriano        Debit  Sicepat Express   \n",
       "4   1110008  2022-06-02   100108    Fanny Utami       Credit  Sicepat Express   \n",
       "5   1110012  2022-07-30   100110   Anita Friska        Debit      JNE Express   \n",
       "\n",
       "   order_price  order_discount     voucher_name  order_total  \n",
       "0       250000           15000         New User       230000  \n",
       "1       620000           40000         New User       575000  \n",
       "2      6000000         1000000         New User      4995000  \n",
       "3      4000000         1000000         New User      2995000  \n",
       "4      2000000               0         New User      1995000  \n",
       "5       490000           35000  Body Soap Promo       445000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_data_from_dwh(query):\n",
    "     # Membuat koneksi ke database\n",
    "    engine = sa.create_engine(warehouse_conn_string)\n",
    "    \n",
    "    # Membuat hasil query menjadi Datafrmae\n",
    "    df = pd.read_sql(query, engine)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_mart = fetch_data_from_dwh(\"\"\"SELECT * FROM dm_sales;\"\"\")\n",
    "df_mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71476a8b-dde7-4794-93da-04c25d3faa0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '163IyMV2W_SR_vYg9IOPYcmQwOtVxSfFQzhPPb9RjBA0',\n",
       " 'updatedRange': 'Sheet3!A1:J7',\n",
       " 'updatedRows': 7,\n",
       " 'updatedColumns': 10,\n",
       " 'updatedCells': 70}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ganti dengan nama google sheets anda\n",
    "sheet = client.open('Contoh Source Data')\n",
    "\n",
    "# ganti sesuai dengan nama sheet didalam google sheets anda\n",
    "# siapkan nama kolom pada sheet di google sheet anda\n",
    "\n",
    "export = sheet.worksheet('Sheet3')\n",
    "export.update([df_mart.columns.values.tolist()] + df_mart.astype(str).values.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
